\section{COCOB: A Master Betting Algorithm for Continuous Coins}
\label{sec:algo}

\begin{algorithm}[ht]
  \begin{algorithmic}
  {
    \STATE{\bfseries Parameters:} $a>2,\delta>1$
    \STATE{\bfseries Initialize:} $\wealth_0=\epsilon,\sg_0=\delta$
    \FOR{$t=1,2,\dots$}
    \STATE{Receive $\theta_{t-1}$ and $\sg_{t-1}$}
    \STATE{Calculate fraction and direction to bet: $\beta_t=2 \, S\left(\frac{4 \theta_{t-1}}{a (\sg_{t-1} + 1)}\right)-1$}
    \STATE{Bet $b_t=\beta_t \wealth_{t-1}$}
    \STATE{Win (or lose) $b_t z_t$}
    \STATE{Update your money: $\wealth_t=\wealth_{t-1}+b_t z_t$}
    %\STATE{Update $\theta_t$: $\theta_t=\theta_{t-1}+z_t$}
    %\STATE{Update $\sg_t$: $\sg_t=\sg_{t-1}+|z_t|$}
    \ENDFOR
  }
  \end{algorithmic}
  \caption{COCOB}
  \label{alg:cocob}
\end{algorithm}

As said in Section~\ref{sec:appl}, we need an efficient \ac{MBA} algorithm for continuous coin betting.
Hence, in this section we show how a very simple algorithm that satisfies Assumption~\ref{assumption:1-d_algo}.

The first observation is that the wealth of the optimal strategy, as proved in Theorems~\ref{thm:oracle_fraction} and \ref{thm:oracle_fraction_changing}, is expected to grow exponential in time depending on $D\left(\frac{1}{2}+\frac{\sum_{t=1}^n g_t}{2 n}\middle\|\frac{1}{2}\right)$. If we try to achieve exactly this term, we are (probably) doomed to use the universal portfolio selection algorithm or to assume a binary coin.
However, we might try to achieve something that is very close to that quantity.
The idea is to sacrifice a bit of the guaranteed growth of the wealth in order to gain generality. In particular we aim at designing a \ac{MBA}.

It is easy to show that
\[
D\left(\frac{1}{2}+\frac{\sum_{t=1}^n g_t}{2 n}\middle\|\frac{1}{2}\right) \geq \frac{(\sum_{t=1}^n g_t)^2}{2 n^2},
\]
where the approximation is very good around $\sum_{t=1}^n g_t=0$ and it is of the order of $\scO(\frac{(\sum_{t=1}^n g_t)^4}{ n^4})$. It was first proposed (but not solved) by~\cite{McMahanA13} to use the above approximation as a target wealth.
Indeed, we show below that it is possible to design a simple algorithm that has an exponential reward that depends on this quantity. Also, our guarantee will be data-dependent and the resulting algorithm will satisfy Assumption~\ref{assumption:1-d_algo}.

The \ac{COCOB} algorithm is shown in Algorithm~\ref{alg:cocob} and we can prove it is a \ac{MBA}.
%Without loss of generality, we will assume that $g_t$ are between $[-1,1]$.
%
\begin{theorem}
\label{theo:cocob}
Let $a\geq2$. Then the function 
\[
f(x,\{z_1, \ldots, z_t\}) := \epsilon \exp\left(\frac{x^2}{a (1+\delta+\sum_{i=1}^{t-1} z_i)} - \sum_{i=1}^{n} \frac{z_i}{a( 1+\delta+\sum_{j=1}^{i-1} z_j) } \right)
\]
and the betting 
\[
b_t:= \gain_{t-1} \left(2 \, S\left(\frac{4 x}{a (1+\delta+\sum_{i=1}^{t-1} z_i)}\right)-1\right),
\]
satisfy Assumption~\ref{assumption:1-d_algo}.
% 
% and start with an amount of money equal to $\epsilon$. Bet at each round a quantity equal to
% $\gain_{t-1} \left(2 \, S\left(\frac{4 \theta_{t-1}}{a (\sg_{t-1} + 1)}\right)-1\right)$, where $S:\R\rightarrow(0,1)$ and $S(x)=\frac{1}{1+exp(-x)}$ and receive the outcome $g_t \in [-1,1]$. Then
% \begin{align*}
% \gain_{n} 
% \geq \epsilon \exp\left(\frac{\theta_{n}^2}{a \sg_{n}} - \sum_{i=1}^{n} \frac{|g_i|}{a( \sg_{i-1} + 1) } \right)
% \geq \epsilon \exp\left(\frac{\theta_{n}^2}{a \sg_{n}} - \frac{1}{a} \ln \left(\sum_{t=1}^n \frac{|g_i|}{\delta}+1\right) \right)~.
% \end{align*}
\end{theorem}
%
Notice that the $a$ regulates the trade-off between the first and second term. When $a=2$, we maximize the contribute of the first term.

\begin{cor}
Set $a=2$ in Algorithm~\ref{alg:cocob}. Then we have that the following hold

\begin{itemize}
\item Feed Algorithm~\ref{alg:cocob} with $\sg_{t-1}=\sum_{i=1}^{t-1} |g_t| + \delta + 1$ and $\theta_{t-1}=|\sum_{i=1}^{t-1} g_i|$.
Algorithm~\ref{alg:cocob} guarantees an exponential reward in $\frac{(\sum_{t=1}^n g_t)^2}{2 \sum_{t=1}^n |g_t|}$ and a regret w.r.t. any real number $u$ of $\tilde{\scO}(|u| \sqrt{\sum_{t=1}^n |g_t|})$.

\item Feed Algorithm~\ref{alg:cocob} with $\sg_{t-1}=\sum_{i=1}^{t-1} \norm{g_t} + \delta + 1$ and $\theta_{t-1}=\norm{\theta_{t-1}}$.
Predicting with $w_t=b_t \frac{\sum_{i=1}^t g_t}{\norm{\sum_{i=1}^t g_t}}$ guarantees a regret w.r.t. any $u \in \fH$ of $\tilde{\scO}(\norm{u} \sqrt{\sum_{t=1}^n \norm{g_t}})$ and an exponential reward in $\frac{(\sum_{t=1}^n g_t)^2}{2 \sum_{t=1}^n \norm{g_t}}$.

\end{itemize}
\end{cor}